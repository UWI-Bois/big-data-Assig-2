{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID : 816000325\n",
    "## Name: Ajay Sieunarine\n",
    "## Email: ajay.sieunarine@my.uwi.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convert the following sentence to a python tuple list of letters and their frequency as they appear. Ignore all non-alpha numeric characters.\n",
    "\n",
    "Sentence: \n",
    "\n",
    "“The quick brown fox jumps over the lazy dog and the fox was very happy”\n",
    "\n",
    "Tuple List:\n",
    "\n",
    "[('h', 1), ('e', 1), ('t', 1), ('q', 1), ('i', 1), ('c', 1), ('u', 1), ('k', 1), ('r', 1), ('b', 1), ('o', 1), ('w', 1), ('n', 1), ('x', 1), ('o', 1), ('f', 1), ('u', 1), ('s', 1), ('j', 1), ('m', 1), ('p', 1), ('r', 1), ('e', 1), ('o', 1), ('v', 1), ('h', 1), ('e', 1), ('t', 1), ('a', 1), ('y', 1), ('z', 1), ('l', 1), ('o', 1), ('d', 1), ('g', 1), ('a', 1), ('d', 1), ('n', 1), ('h', 1), ('e', 1), ('t', 1), ('x', 1), ('o', 1), ('f',1), ('a', 1), ('s', 1), ('w', 1), ('y', 1), ('r', 1), ('e', 1), ('v', 1), ('a', 1), ('h', 1), ('y', 1), ('p', 2)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the quick brown fox jumps over the lazy dog and the fox was very happy\n",
      "[('t', 1), ('h', 1), ('e', 1), (' ', 1), ('q', 1), ('u', 1), ('i', 1), ('c', 1), ('k', 1), (' ', 1), ('b', 1), ('r', 1), ('o', 1), ('w', 1), ('n', 1), (' ', 1), ('f', 1), ('o', 1), ('x', 1), (' ', 1), ('j', 1), ('u', 1), ('m', 1), ('p', 1), ('s', 1), (' ', 1), ('o', 1), ('v', 1), ('e', 1), ('r', 1), (' ', 1), ('t', 1), ('h', 1), ('e', 1), (' ', 1), ('l', 1), ('a', 1), ('z', 1), ('y', 1), (' ', 1), ('d', 1), ('o', 1), ('g', 1), (' ', 1), ('a', 1), ('n', 1), ('d', 1), (' ', 1), ('t', 1), ('h', 1), ('e', 1), (' ', 1), ('f', 1), ('o', 1), ('x', 1), (' ', 1), ('w', 1), ('a', 1), ('s', 1), (' ', 1), ('v', 1), ('e', 1), ('r', 1), ('y', 1), (' ', 1), ('h', 1), ('a', 1), ('p', 1), ('p', 1), ('y', 1)]\n"
     ]
    }
   ],
   "source": [
    "foxy_sentence = \"The quick brown fox jumps over the lazy dog and the fox was very happy\"\n",
    "new_sentence = \"\"\n",
    "\n",
    "for i in foxy_sentence:\n",
    "    if i.isalpha() or i == \" \":\n",
    "        new_sentence += i.lower()\n",
    "\n",
    "print (new_sentence)\n",
    "\n",
    "foxy_dict = {}\n",
    "foxy_array = []\n",
    "foxy_tuple = []\n",
    "\n",
    "n = 0\n",
    "for i in new_sentence:\n",
    "    temp_dict = {}\n",
    "    temp_dict[i] = 1\n",
    "    temp_tuple = tuple(temp_dict.items())\n",
    "    foxy_tuple += temp_tuple\n",
    "    n += 1\n",
    "    \n",
    "\n",
    "# print(foxy_dict)\n",
    "\n",
    "# print(new_sentence)\n",
    "    \n",
    "# all_freq = {}\n",
    "\n",
    "# for i in new_sentence:\n",
    "#     if i in all_freq:\n",
    "#         all_freq[i] += 1\n",
    "#     else:\n",
    "#         all_freq[i] = 1\n",
    "\n",
    "# print(all_freq)\n",
    "# type(all_freq)\n",
    "\n",
    "# foxy_tuple = all_freq.items()\n",
    "\n",
    "# foxy_tuple = foxy_dict.items()\n",
    "\n",
    "\n",
    "# print(foxy_dict)\n",
    "\n",
    "print(foxy_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a PySpark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local appName=Assignment 2>\n"
     ]
    }
   ],
   "source": [
    "import pyspark # library for the spark session -> spark will allow us to manipualte RDDs\n",
    "from pyspark.sql import SparkSession # spark session -> allow for dataframe and sql functionality\n",
    "from pyspark.sql import Row # allow us to represent rows from dataframes\n",
    "from pyspark.sql.types import * # get/set datatypes of cols\n",
    "from pyspark.sql.functions import * # epic built-in functions \n",
    "from pyspark.ml.linalg import DenseVector # for linear algebra, uses numpy arrays,\n",
    "from pyspark.ml.feature import StandardScaler # standardize features by removing the mean, and scaling to unit variance\n",
    "\n",
    "# init spark sesh\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Assignment 2\") \\\n",
    "    .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert the list of tuples to a PySpark RDD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('t', 1), ('h', 1), ('e', 1), ('q', 1), ('u', 1), ('i', 1), ('c', 1), ('k', 1), ('b', 1), ('r', 1), ('o', 1), ('w', 1), ('n', 1), ('f', 1), ('o', 1), ('x', 1), ('j', 1), ('u', 1), ('m', 1), ('p', 1), ('s', 1), ('o', 1), ('v', 1), ('e', 1), ('r', 1), ('t', 1), ('h', 1), ('e', 1), ('l', 1), ('a', 1), ('z', 1), ('y', 1), ('d', 1), ('o', 1), ('g', 1), ('a', 1), ('n', 1), ('d', 1), ('t', 1), ('h', 1), ('e', 1), ('f', 1), ('o', 1), ('x', 1), ('w', 1), ('a', 1), ('s', 1), ('v', 1), ('e', 1), ('r', 1), ('y', 1), ('h', 1), ('a', 1), ('p', 1), ('p', 1), ('y', 1)]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(foxy_tuple)\n",
    "type(rdd)\n",
    "print(rdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using the methods of PySpark RDD display the letter count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 4), ('b', 1), ('c', 1), ('d', 2), ('e', 5), ('f', 2), ('g', 1), ('h', 4), ('i', 1), ('j', 1), ('k', 1), ('l', 1), ('m', 1), ('n', 2), ('o', 5), ('p', 3), ('q', 1), ('r', 3), ('s', 2), ('t', 3), ('u', 2), ('v', 2), ('w', 2), ('x', 2), ('y', 3), ('z', 1)]\n"
     ]
    }
   ],
   "source": [
    "rdd_grouped = rdd.reduceByKey(lambda x, y: x+y)\n",
    "rdd_grouped = rdd_grouped.sortByKey()\n",
    "print(rdd_grouped.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using the methods of PySpark RDD display the letter and number of times they appear in each word in the sentence.\n",
    "\n",
    "Sample:\n",
    "\n",
    "[('a', [1, 1, 1, 1]), ('e', [1, 1, 1, 1, 1]), ('i', [1]), ('m', [1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
